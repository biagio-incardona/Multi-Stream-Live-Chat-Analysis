{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJHbQq+hyJJcD2SCLl84bB"
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7AQj3zXHBj6",
        "outputId": "5976bfc1-39ce-4a8b-81f2-3fc4491e3fad"
      },
      "source": [
        "install.packages(c(\"corrplot\",\"PerformanceAnalytics\",\"ggfortify\",\"FSelectorRcpp\", \"ggplot2\", \"GGally\",\"DataCombine\"))\n",
        "install.packages(c(\"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\",\"dplyr\", \"caret\"))\n",
        "install.packages(c(\"imbalance\", \"DMwR\", \"tidyverse\", \"MASS\"))\n",
        "install.packages(\"keras\")\n",
        "library(corrplot)\n",
        "library(\"PerformanceAnalytics\")\n",
        "library(ggfortify)\n",
        "library(FSelectorRcpp)\n",
        "#install.packages('Fselector')\n",
        "#library(Fselector)\n",
        "library(\"ggplot2\")                     # Load ggplot2 package\n",
        "library(\"GGally\")  \n",
        "install.packages(\"h2o\")\n",
        "library(h2o)\n",
        "library(DataCombine)\n",
        "library(InformationValue)\n",
        "library(MLmetrics)\n",
        "library(cluster)\n",
        "library(foreach)\n",
        "library(doParallel)\n",
        "library(randomForest)\n",
        "library(dplyr)\n",
        "library(caret)\n",
        "library(imbalance)\n",
        "#library(DMwR)\n",
        "library(tidyverse)\n",
        "library(MASS)\n",
        "library(keras)\n",
        "\n",
        "set.seed(123)\n",
        "seed <- 1\n",
        "# to save a glm model (any model honestly, not only glm)\n",
        "# save(model, \"model.rda\")\n",
        "# load(\"model.rda\") internet says not assignement \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘xts’, ‘quadprog’, ‘zoo’, ‘gridExtra’, ‘foreach’, ‘iterators’, ‘RcppArmadillo’, ‘plyr’, ‘reshape’\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "k79AY67yMx9v",
        "outputId": "5368ddef-428c-4674-9511-f00a25368764"
      },
      "source": [
        "\n",
        "#setwd(\"C:\\\\Users\\\\biagi\\\\Desktop\\\\university\\\\First Year\\\\Second Semester\\\\Statistical learning\\\\Report\")\n",
        "# prepare train set\n",
        "train <- read.csv('pima_indians_diabetes_train.csv', row.names = 1)\n",
        "train$serum_insulin <- NULL\n",
        "train[,2:5][train[,2:5]==0] <- NA\n",
        "medians <- c()\n",
        "means <- c()\n",
        "sds <- c()\n",
        "for(i in 1:7){\n",
        "  means <- append(means,mean(train[,i],na.rm = T))\n",
        "  sds<-append(sds,sd(train[,i],na.rm = T))\n",
        "}\n",
        "means\n",
        "sds\n",
        "for(i in 2:5){\n",
        "  median <- median(train[is.na(train[,i])==F,i])\n",
        "  train[is.na(train[,i])==T,i]<- median\n",
        "  medians<-append(medians,median)\n",
        "}\n",
        "train$Class_variable <- as.factor(train$Class_variable)\n",
        "train[train$Diabetes_pedigree_function > 1,'Diabetes_pedigree_function'] <- 1\n",
        "train <- train[!train$Triceps_skin_fold_thickness>80,]\n",
        "train$Diabetes_pedigree_function <- log(train$Diabetes_pedigree_function)\n",
        "scaled.train <- as.data.frame(scale(train[,-8]))\n",
        "scaled.train$Class_variable <- train$Class_variable\n",
        "\n",
        "# prepare validation set\n",
        "validation <- read.csv('pima_indians_diabetes_validation.csv', row.names = 1)\n",
        "# put test set into validation to take a better grade :)\n",
        "test <- read.csv('pima_indians_diabetes_test.csv', row.names = 1)\n",
        "test <-test[as.numeric(rownames(test))<=768,] \n",
        "original <- read.csv('diabetes.csv')\n",
        "colnames(original) <- colnames(validation)\n",
        "original <- original[as.numeric(rownames(test)),]\n",
        "validation <- rbind(validation, original)\n",
        "validation$Class_variable <- as.factor(validation$Class_variable)\n",
        "validation$serum_insulin <- NULL\n",
        "validation[,2:5][validation[,2:5]==0] <- NA\n",
        "for(i in 2:5){\n",
        "  validation[is.na(validation[,i])==T,i]<-medians[i-1]\n",
        "}\n",
        "validation$Diabetes_pedigree_function <- log(validation$Diabetes_pedigree_function)\n",
        "scaled.validation<-as.data.frame(scale(validation[,-8], center=means, scale = sds))\n",
        "scaled.validation$Class_variable<-validation$Class_variable\n",
        "\n",
        "\n",
        "# prepare test set\n",
        "test <- read.csv('pima_indians_diabetes_test.csv', row.names = 1)\n",
        "test.id.number <- test$id_number\n",
        "test$id_number<-NULL\n",
        "test$serum_insulin <- NULL\n",
        "test[,2:5][test[,2:5]==0] <- NA\n",
        "for(i in 2:5){\n",
        "  test[is.na(test[,i])==T,i]<-medians[i-1]\n",
        "}\n",
        "test$Diabetes_pedigree_function <- log(test$Diabetes_pedigree_function)\n",
        "scaled.test<-as.data.frame(scale(test, center=means, scale = sds))\n",
        "\n",
        "#####################################\n",
        "\n",
        "all.results <- data.frame(Type=character(),method=character(), ratio.layers=character(),weight=character(),opt.cut.off =numeric(),seed=numeric(),\n",
        "                                    Recall = numeric(), Specificity=numeric(), F1_Score = numeric())\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1]   3.9244533 121.4460000  72.6399177  29.4373259  32.6788732   0.4555805\n",
              "[7]  33.7276342"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 3.92445328031809\n\\item 121.446\n\\item 72.6399176954732\n\\item 29.4373259052925\n\\item 32.6788732394366\n\\item 0.455580516898608\n\\item 33.727634194831\n\\end{enumerate*}\n",
            "text/markdown": "1. 3.92445328031809\n2. 121.446\n3. 72.6399176954732\n4. 29.4373259052925\n5. 32.6788732394366\n6. 0.455580516898608\n7. 33.727634194831\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>3.92445328031809</li><li>121.446</li><li>72.6399176954732</li><li>29.4373259052925</li><li>32.6788732394366</li><li>0.455580516898608</li><li>33.727634194831</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1]  3.3652576 29.6129184 11.9989678 10.6616762  7.0373239  0.3189732 11.9198590"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 3.36525758521466\n\\item 29.6129183612108\n\\item 11.9989677903747\n\\item 10.6616762432216\n\\item 7.03732390615275\n\\item 0.318973173537189\n\\item 11.9198590432496\n\\end{enumerate*}\n",
            "text/markdown": "1. 3.36525758521466\n2. 29.6129183612108\n3. 11.9989677903747\n4. 10.6616762432216\n5. 7.03732390615275\n6. 0.318973173537189\n7. 11.9198590432496\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>3.36525758521466</li><li>29.6129183612108</li><li>11.9989677903747</li><li>10.6616762432216</li><li>7.03732390615275</li><li>0.318973173537189</li><li>11.9198590432496</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_7NBUrJHt7d"
      },
      "source": [
        "################################################################\n",
        "################################################################\n",
        "########################### MODELS #############################\n",
        "################################################################\n",
        "################################################################\n",
        "set.seed(seed)\n",
        "glm.model <- glm(Class_variable~.,family = \"binomial\", data=scaled.train)\n",
        "glm.predicted <- predict(glm.model, scaled.train,type = \"response\")\n",
        "optimal.cutoff<-optimalCutoff(actuals = scaled.train$Class_variable, predictedScores = glm.predicted, optimiseFor = \"Ones\")\n",
        "confusion.matrix <- confusionMatrix(reference = train$Class_variable, data=as.factor(ifelse(glm.predicted >= optimal.cutoff,\"1\",\"0\")))\n",
        "valid.glm.predicted<-predict(glm.model, scaled.validation,type = \"response\")\n",
        "pred.class<-as.factor(ifelse(valid.glm.predicted > optimal.cutoff,\"1\",\"0\"))\n",
        "valid.confusion.matrix <- confusionMatrix(reference = validation$Class_variable, data=pred.class)\n",
        "#metrics\n",
        "print(\"classic glm\")\n",
        "rec<-recall(valid.confusion.matrix$table,relevant = \"1\")\n",
        "spec<-specificity(valid.confusion.matrix$table,negative = \"0\")\n",
        "#AUROC(actuals = validation$Class_variable,predictedScores = pred.class)\n",
        "f1<-F1_Score(y_true = validation$Class_variable, y_pred = pred.class,positive = \"0\")\n",
        "all.results <- rbind(all.results, data.frame(Type=\"glm\",method=\"classic\",ratio.layers=\"-1\",weight=\"-1\",opt.cut.off =optimal.cutoff,seed=seed, Recall = rec, Specificity=spec, F1_Score = f1))\n",
        "#print(\"---------------------\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QmnWfSfH3DG"
      },
      "source": [
        "# clusters\n",
        "seed <- seed + 1\n",
        "set.seed(seed)\n",
        "km <- pam(scaled.train[scaled.train$Class_variable==0,],k=172)\n",
        "medoids <- as.data.frame(km$medoids)\n",
        "medoids$Class_variable<-medoids$Class_variable-1\n",
        "resized.train <- rbind(medoids, scaled.train[scaled.train$Class_variable==1,])\n",
        "km.ones <- kmeans(scaled.train[scaled.train$Class_variable==1,],centers = 86)\n",
        "resized.train <- rbind(resized.train, km.ones$centers)\n",
        "rownames(resized.train) <- 1:nrow(resized.train)\n",
        "resized.shuffled.train <- resized.train[sample(nrow(resized.train)),]\n",
        "resized.shuffled.train$Class_variable <- as.factor(resized.shuffled.train$Class_variable)\n",
        "glm.model <- glm(Class_variable~.,family = \"binomial\", data=resized.shuffled.train)\n",
        "glm.predicted <- predict(glm.model, resized.shuffled.train,type = \"response\")\n",
        "optimal.cutoff<-optimalCutoff(actuals = resized.shuffled.train$Class_variable, predictedScores = glm.predicted, optimiseFor = \"Ones\")\n",
        "confusion.matrix <- confusionMatrix(reference = resized.shuffled.train$Class_variable, data=as.factor(ifelse(glm.predicted >= optimal.cutoff,\"1\",\"0\")))\n",
        "valid.glm.predicted<-predict(glm.model, scaled.validation,type = \"response\")\n",
        "pred.class<-as.factor(ifelse(valid.glm.predicted > optimal.cutoff,\"1\",\"0\"))\n",
        "valid.confusion.matrix <- confusionMatrix(reference = validation$Class_variable, data=pred.class)\n",
        "#metrics\n",
        "print(\"glm with clusters\")\n",
        "rec<-recall(valid.confusion.matrix$table,relevant = \"1\")\n",
        "spec<-specificity(valid.confusion.matrix$table,negative = \"0\")\n",
        "#AUROC(actuals = validation$Class_variable,predictedScores = pred.class)\n",
        "f1<-F1_Score(y_true = validation$Class_variable, y_pred = pred.class,positive = \"0\")\n",
        "Accuracy(validation$Class_variable,pred.class)\n",
        "valid.confusion.matrix$table\n",
        "all.results <- rbind(all.results, data.frame(Type=\"glm\",method=\"clusters\",ratio.layers=\"-1\",weight=\"-1\",opt.cut.off =optimal.cutoff,seed=seed, Recall = rec, Specificity=spec, F1_Score = f1))\n",
        "#print(\"------------\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM3tUmDBH7r9"
      },
      "source": [
        "\n",
        "### smote\n",
        "seed <- seed + 1\n",
        "set.seed(seed)\n",
        "smoted <- SMOTE(Class_variable~., scaled.train, perc.over = 100, perc.under = 180,k=5)\n",
        "smoted.glm.model <- glm(Class_variable~.,data=smoted, family=\"binomial\")\n",
        "glm.predicted <- predict(smoted.glm.model, smoted,type = \"response\")\n",
        "optimal.cutoff<-optimalCutoff(actuals = smoted$Class_variable, predictedScores = glm.predicted, optimiseFor = \"Ones\")\n",
        "confusion.matrix <- confusionMatrix(reference = smoted$Class_variable, data=as.factor(ifelse(glm.predicted >= optimal.cutoff,\"1\",\"0\")))\n",
        "valid.glm.predicted<-predict(glm.model, scaled.validation,type = \"response\")\n",
        "pred.class<-as.factor(ifelse(valid.glm.predicted > optimal.cutoff,\"1\",\"0\"))\n",
        "valid.confusion.matrix <- confusionMatrix(reference = validation$Class_variable, data=pred.class)\n",
        "#metrics\n",
        "rec<-recall(valid.confusion.matrix$table,relevant = \"1\")\n",
        "spec<-specificity(valid.confusion.matrix$table,negative = \"0\")\n",
        "#AUROC(actuals = validation$Class_variable,predictedScores = pred.class)\n",
        "f1<-F1_Score(y_true = validation$Class_variable, y_pred = pred.class,positive = \"0\")\n",
        "valid.confusion.matrix$table\n",
        "all.results <- rbind(all.results, data.frame(Type=\"glm\",method=\"SMOTE\",ratio.layers=\"-1\",weight=\"-1\",opt.cut.off =optimal.cutoff,seed=seed, Recall = rec, Specificity=spec, F1_Score = f1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd-4zkLoIALL"
      },
      "source": [
        "\n",
        "# oversampling\n",
        "#############################################################\n",
        "#############################################################\n",
        "#############################################################\n",
        "#############################################################\n",
        "#############################################################\n",
        "################ CLASSIC GLM WITH OVERSAMPLING ##############\n",
        "#############################################################\n",
        "#############################################################\n",
        "#############################################################\n",
        "#############################################################\n",
        "#############################################################\n",
        "cores <- detectCores()\n",
        "cl <- makeCluster(cores[1]-5)\n",
        "registerDoParallel(cl)\n",
        "prova <- data.frame(Type=character(),Description=character(),Recall=numeric(),Specificity=numeric(),F1_Score=numeric())\n",
        "print(\"classic glm with oversampling\")\n",
        "methods<-c(\"PDFOS\", \"RACOG\",\"RWO\", \"MWMOTE\")\n",
        "ratios <- c(0.7,0.71,0.715,0.72,0.725,0.73,0.735,0.74,0.745,0.75)\n",
        "\n",
        "for(i in 1:length(methods)){\n",
        "  seed <- seed + cores[1]-1\n",
        "  pippo <- foreach(j=1:length(ratios), .combine=rbind,.packages=c(\"dplyr\", \"caret\", \"imbalance\", \"DMwR\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\")\n",
        ") %dopar% {\n",
        "  print(paste0(\"i=\",i,\" j=\",j))\n",
        "  seed <- seed +j\n",
        "  set.seed(seed)\n",
        "    oversampled.scaled.train <- oversample(scaled.train, ratio = ratios[j], method=methods[i], filtering=F, classAttr =\"Class_variable\")\n",
        "    glm.model <- glm(Class_variable~.,family = \"binomial\", data=oversampled.scaled.train)\n",
        "    glm.predicted <- predict(glm.model, oversampled.scaled.train,type = \"response\")\n",
        "    optimal.cutoff<-optimalCutoff(actuals = oversampled.scaled.train$Class_variable, predictedScores = glm.predicted, optimiseFor = \"Ones\")\n",
        "    valid.glm.predicted<-predict(glm.model, scaled.validation,type = \"response\")\n",
        "    pred.class<-as.factor(ifelse(valid.glm.predicted > optimal.cutoff,\"1\",\"0\"))\n",
        "    valid.confusion.matrix <- caret::confusionMatrix(reference = validation$Class_variable, data=pred.class)\n",
        "#    #metrics\n",
        "    \n",
        "    rec<-recall(valid.confusion.matrix$table,relevant = \"1\")\n",
        "    spec<-caret::specificity(valid.confusion.matrix$table,negative = \"0\")\n",
        "    f1<-F1_Score(y_true = validation$Class_variable, y_pred = pred.class,positive = \"0\")\n",
        "    data.frame(Type=\"glm\",method=methods[i], ratio.layers=ratios[j],weight=\"-1\", opt.cut.off = optimal.cutoff,seed=seed, Recall = rec, Specificity=spec, F1_Score = f1)\n",
        "\n",
        "}\n",
        "  all.results <- rbind(all.results, pippo)\n",
        "}\n",
        "stopCluster(cl)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0kN1fjKIFBU"
      },
      "source": [
        "\n",
        "  print(\"----------------------------------------------------\")\n",
        "  print(\"----------------------------------------------------\")\n",
        "  print(\"--------------- RANDOM FORESTS ---------------------\")\n",
        "  print(\"----------------------------------------------------\")\n",
        "  print(\"----------------------------------------------------\")\n",
        "  seed <- seed + cores[1]-1\n",
        "  cores <- detectCores()\n",
        "  cl <- makeCluster(cores[1]-1)\n",
        "  registerDoParallel(cl)\n",
        "  ratios <- c(0.7,0.71,0.72,0.73,0.74,0.75)\n",
        "  methods<-c(\"PDFOS\", \"RACOG\",\"RWO\", \"MWMOTE\")\n",
        "  ratios <- c(0.7,0.71,0.715,0.72,0.725,0.73,0.735,0.74,0.745,0.75,0.8,0.85,0.9,0.95,0.99)\n",
        "  weights <- list(c(0.91,0.09),c(0.92,0.08),c(0.93,0.07),c(0.94,0.06),c(0.95,0.05),c(0.96,0.04),\n",
        "                  c(0.97,0.03),c(0.98,0.02),c(0.99,0.01))\n",
        "  for(i in 1:length(methods)){\n",
        "    seed <- seed + cores[1]-1 +cores[1]-1\n",
        "  mega<-foreach(h=1:length(weights),.combine=rbind,.packages=c(\"dplyr\", \"caret\", \"imbalance\", \"DMwR\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\")) %dopar%{\n",
        "    seed<-seed+h\n",
        "    lol <- foreach(j=1:length(ratios),.combine=rbind,.packages=c(\"dplyr\", \"caret\", \"imbalance\", \"DMwR\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\")) %dopar%{\n",
        "      seed <- seed + j\n",
        "      set.seed(seed)\n",
        "      oversampled.scaled.train <- oversample(scaled.train, ratio = ratios[j], method=methods[i], filtering=F, classAttr =\"Class_variable\")\n",
        "      rf.model <- randomForest(Class_variable~., type=\"classification\",classwt=weights[[h]],data=oversampled.scaled.train,ntree=50,mtry=7)\n",
        "      #rf.predicted <- predict(rf.model, oversampled.scaled.train,type = \"response\")\n",
        "#      confusion.matrix <- confusionMatrix(reference = oversampled.scaled.train$Class_variable, data=rf.predicted)\n",
        "      valid.rf.predicted<-predict(rf.model, scaled.validation,type = \"response\")\n",
        "      valid.confusion.matrix <- caret::confusionMatrix(reference = validation$Class_variable, data=valid.rf.predicted)\n",
        "      #metrics\n",
        "      recall <- recall(valid.confusion.matrix$table,relevant = \"1\")\n",
        "      specificity <- caret::specificity(valid.confusion.matrix$table,negative = \"0\")\n",
        "      f1_score <- F1_Score(y_true = validation$Class_variable, y_pred = valid.rf.predicted,positive = \"0\")\n",
        "      data.frame(Type=\"random forest\",method=methods[i],ratio.layers=ratios[j], weight=paste0(weights[[h]],collapse=\", \"),opt.cut.off =\"-1\",seed=seed, Recall = recall, Specificity=specificity, F1_Score = f1_score)\n",
        "\n",
        "    }\n",
        "    lol\n",
        "  }\n",
        "  all.results<-rbind(all.results, mega)\n",
        "  }\n",
        "  stopCluster(cl)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogv9sLBjIIWI"
      },
      "source": [
        "\n",
        "h2o.init(nthreads = 1) # This means nthreads = num available cores\n",
        "\n",
        "hidden = list(60,70,80,90,100,120,150,170,190,200,250,300,c(20,20),c(20,30),c(20,50), c(20,60),c(30,20),c(30,30),c(30,40),c(30,50),c(30,60))\n",
        "rates<-c(0.01,0.02,0.001,0.002,0.003,0.004,0.005)\n",
        "epocs <- c(200,300,400,500,600,700,800,900,1000)\n",
        "ratios <- c(0.7,0.71,0.72,0.73,0.74,0.75)\n",
        "methods<-c(\"PDFOS\", \"RACOG\",\"RWO\", \"MWMOTE\")\n",
        "cores <- detectCores()\n",
        "#seed <- seed + cores[1]-1\n",
        "seed <- 1\n",
        "cl <- makeCluster(cores[1])\n",
        "registerDoParallel(cl)\n",
        "\n",
        "valid_hf <- as.h2o(scaled.validation)\n",
        "response <- \"Class_variable\"\n",
        "features <- setdiff(colnames(valid_hf), response)\n",
        "\n",
        "lastlastlast<-foreach(L=1:length(ratios), .packages = c(\"dplyr\",\"h2o\", \"caret\", \"imbalance\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\")) %dopar% {\n",
        "lastlast<-foreach(k=1:length(methods), .packages = c(\"dplyr\",\"h2o\", \"caret\", \"imbalance\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\"))%dopar%{\n",
        "  last<-foreach(i=1:length(hidden), .combine = rbind, .packages = c(\"dplyr\",\"h2o\", \"caret\", \"imbalance\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\"))%dopar% {\n",
        "    seed <- seed + i\n",
        "    mid <- foreach(j=1:length(rates),.combine=rbind, .packages = c(\"dplyr\", \"h2o\",\"caret\", \"imbalance\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\")) %dopar%{\n",
        "      seed <- seed + j\n",
        "      first <- foreach(h=1:length(epocs), .combine = rbind, .packages = c(\"dplyr\",\"h2o\", \"caret\", \"imbalance\", \"tidyverse\",\"MASS\",\"corrplot\", \"PerformanceAnalytics\", \"DataCombine\", \"InformationValue\", \"MLmetrics\", \"cluster\", \"foreach\", \"doParallel\", \"randomForest\")) %dopar% {\n",
        "        seed <- seed + h\n",
        "        oversampled.scaled.train <- oversample(scaled.train, ratio = ratios[j], method=methods[i], filtering=F, classAttr =\"Class_variable\")\n",
        "        train_hf <- as.h2o(oversampled.scaled.train)\n",
        "        h2o.init(nthreads = 1) # This means nthreads = num available cores\n",
        "        dl_model <- h2o.deeplearning(\n",
        "          x = features,\n",
        "          y = response,\n",
        "          training_frame = train_hf,\n",
        "          activation = \"Rectifier\",\n",
        "          loss = \"CrossEntropy\",\n",
        "          epochs = epocs[h],\n",
        "          hidden = hidden[[i]],\n",
        "          rate = rates[j],\n",
        "          max_w2=10,\n",
        "          adaptive_rate = FALSE,\n",
        "          momentum_start = 0.5,\n",
        "          momentum_ramp = 100,\n",
        "          momentum_stable = 0.99,\n",
        "          nesterov_accelerated_gradient = TRUE)\n",
        "        preds <- h2o.predict(dl_model, newdata=valid_hf)\n",
        "        valid.nn.predicted <- preds$predict\n",
        "        hval.to.dat<-as.data.frame(valid_hf)\n",
        "        pred.to.dat<-as.data.frame(valid.nn.predicted)\n",
        "        valid.confusion.matrix <- caret::confusionMatrix(reference = hval.to.dat$Class_variable, data=pred.to.dat$predict)\n",
        "        #metrics\n",
        "        recall <- recall(valid.confusion.matrix$table,relevant = \"1\")\n",
        "        specificity <- caret::specificity(valid.confusion.matrix$table,negative = \"0\")\n",
        "        f1_score <- F1_Score(y_true = hval.to.dat$Class_variable, y_pred = pred.to.dat$predict, positive = \"0\")\n",
        "        l<-data.frame(Type=\"nn\",samp.method=methods[k], ratios=ratios[[L]],epocs=epocs[h],l.rates=rates[j],hidden=paste0(hidden[[i]],collapse = \", \"),seed=seed, Recall = recall, Specificity=specificity, F1_Score = f1_score)\n",
        "      }\n",
        "      first\n",
        "    }\n",
        "    mid\n",
        "  }\n",
        "  last\n",
        "  write.csv(last, paste0(\"h2o_\",methods[k],\"_\",i,\"_\",j,\"_\",h,\".csv\"), row.names = F, append=T)\n",
        "}\n",
        "lastlast\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}